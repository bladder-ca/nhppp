
\begin{table}
\small
\centering
\begin{tabular}{lll}
\toprule
\textbf{Metric} &
\textbf{Definition} &
\textbf{Description} \\
\midrule
%
Bias in mean & 
$B_\mu = \frac{1}{J}\sum_j{n_j} - N$ & 
\begin{tabular}[c]{@{}l@{}}
Mean difference from target in\\
the number of counts. 
\end{tabular} \\
\addlinespace
%
Relative bias in mean & 
$B_{\mu,rel} = \frac{B_\mu}{N}$ & 
\begin{tabular}[c]{@{}l@{}}
Mean proportional difference\\
from target in the number of\\
counts.
\end{tabular} \\
\addlinespace
%
Bias in variance & 
$B_V = \frac{1}{J}\sum_j{ \big( n_j - \frac{1}{J} \sum_j {n_j} \big)^2} - V$ & 
\begin{tabular}[c]{@{}l@{}}
Mean difference from target\\ 
in variance of counts. 
\end{tabular} \\
\addlinespace
%
Relative bias in variance & 
$B_{V, rel} = \frac{B_V}{V}$ & 
\begin{tabular}[c]{@{}l@{}}
Mean proportional difference\\ 
from target in variance of\\ 
counts. 
\end{tabular} \\
\addlinespace
%
\begin{tabular}[c]{@{}l@{}} Equal-tailed $p$\% \\confidence interval bounds\end{tabular} & 
$n_{[p/2]}, n_{[1-p/2]}$ & 
\begin{tabular}[c]{@{}l@{}}
Quantiles of the empirical\\ 
distribution of counts.
\end{tabular} \\
\addlinespace
%
Goodness of fit $p$~value & 
Statistic $\sum_x \frac{(O_x - E_x)^2}{E_x} \sim \chi^2_{U-L+1}  $ & 
\begin{tabular}[c]{@{}l@{}} 
Left-tail $p$~value.\\
$p$~values near 1 imply good fit.
\end{tabular} \\
\addlinespace
%
Wasserstein-1 distance& 
\begin{tabular}[c]{@{}l@{}}
$W_1$, the smallest rearrangement \\
of probability mass so that one\\
distribution matches the other.   
\end{tabular} & 
$W_1 = 0$ implies good fit \\
\addlinespace
%
$p$~value for $W_1\ne0$ &  
Asymptotic theory $p$~value & 
\begin{tabular}[c]{@{}l@{}} 
Two-sided $p$~value.\\
$p$~values near 1 imply good fit.
\end{tabular} \\
\bottomrule
\end{tabular}
\caption{Simulation metrics for the number of counts. In the Table, $j \in [J]$ indexes simulations, $n_j$ is the number of counts in simulation $j$, $N = \Lambda(6\pi)-\Lambda(0)$ is the theoretical mean number of counts, and $V = \Lambda(6\pi)-\Lambda(0)=N$ the theoretical variance. The lower and upper bounds of an equal-tailed $p$\% confidence interval, $p \in \{95, 90, 75, 50\}$, are denoted with $n_{[p/2]}, n_{[1-p/2]}$, respectively. 
For the goodness of fit, we created bins $[0, L), [L, L+1), \dots, [U, \infty)$, where $L, U$ are the $0.001$ and $0.999$ percentiles of the Poisson distribution with parameter $\Lambda(6\pi) - \Lambda(0)$. 
We indexed bins with $x \in \{ 1, \dots, U-L+2\}$. 
%In the example, $L = \Sexpr{stats::qpois(0.001, L(6*pi)-L(0))}$ and $U = \Sexpr{stats::qpois(0.999, L(6*pi)-L(0))}$. 
The goodness of fit statistic contrasts the observed ($O_x$) versus expected ($E_x$) numbers of events over the bins and it is compared with a $\chi^2_{U-L+1}$ distribution to obtain a $p$~value.
}
\label{tab:sim_metrics}
\end{table}
