%%%%%%#%#!TEX root = nhppp.tex
% !Rnw weave = knitr

\documentclass[article,nojss]{jss}
% \documentclass[article]{jss}

%% -- LaTeX packages and custom commands ---------------------------------------

%% recommended packages
\usepackage{orcidlink,thumbpdf,lmodern}

%% another package (only for this demo article)
\usepackage{framed}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{bm, bbm}
\usepackage{algorithm, algpseudocode}

%% new custom commands
\newcommand{\indep}{\perp \!\!\! \perp}
\newcommand{\der}[2]{\frac{d {#1}} {d{#2}}}


\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}
\newcommand{\BI}{\mathbb I}
\newcommand{\BC}{\mathbb C}		\newcommand{\BH}{\mathbb H}
\newcommand{\BR}{\mathbb R}		\newcommand{\BD}{\mathbb D}
\newcommand{\BN}{\mathbb N}		\newcommand{\BQ}{\mathbb Q}
\newcommand{\BS}{\mathbb S}		\newcommand{\BZ}{\mathbb Z}
\newcommand{\BF}{\mathbb F}			\newcommand{\BT}{\mathbb T}
\newcommand{\CA}{\mathcal A}		\newcommand{\CB}{\mathcal B}
\newcommand{\CC}{\mathcal C}		\newcommand{\calD}{\mathcal D}
\newcommand{\CE}{\mathcal E}		\newcommand{\CF}{\mathcal F}
\newcommand{\CG}{\mathcal G}		\newcommand{\CH}{\mathcal H}
\newcommand{\CI}{\mathcal I}		\newcommand{\CJ}{\mathcal J}
\newcommand{\CK}{\mathcal K}		\newcommand{\CL}{\mathcal L}
\newcommand{\CM}{\mathcal M}		\newcommand{\CN}{\mathcal N}
\newcommand{\CO}{\mathcal O}		\newcommand{\CP}{\mathcal P}
\newcommand{\CQ}{\mathcal Q}		\newcommand{\CR}{\mathcal R}
\newcommand{\CS}{\mathcal S}		\newcommand{\CT}{\mathcal T}
\newcommand{\CU}{\mathcal U}		\newcommand{\CV}{\mathcal V}
\newcommand{\CW}{\mathcal W}		\newcommand{\CX}{\mathcal X}
\newcommand{\CY}{\mathcal Y}		\newcommand{\CZ}{\mathcal Z}




% \SweaveOpts{prefix.string=figures/nhppp, concordance=FALSE}

%\VignetteIndexEntry{a guide to the nhppp package}
%\VignetteKeywords{nhppp}
%\VignetteDepends{nhppp,rstream,lifecycle}
%\VignettePackage{nhppp}


%% -- Article metainformation (author, title, ...) -----------------------------

%% - \author{} with primary affiliation (and optionally ORCID link)
%% - \Plainauthor{} without affiliations
%% - Separate authors by \And or \AND (in \author) or by comma (in \Plainauthor).
%% - \AND starts a new line, \And does not.
\author{Thomas A. Trikalinos~\orcidlink{0000-0002-3990-1848}\\Brown University
   \And Yuliia Sereda~\orcidlink{https://orcid.org/0000-0002-4017-4561}\\Brown University}
\Plainauthor{Thomas A. Trikalinos, Yuliia Sereda}

%% - \title{} in title case
%% - \Plaintitle{} without LaTeX markup (if any)
%% - \Shorttitle{} with LaTeX markup (if any), used as running title
\title{Simulating Nonhomogeneous Poisson Point Processes in \proglang{R}}
\Plaintitle{Simulating Nonhomogeneous Poisson Point Processes in R}
\Shorttitle{Simulating NHPPPs in R}

%% - \Abstract{} almost as usual
\Abstract{
 We introduce the \pkg{nhppp} package for simulating events from one dimensional nonhomogeneous Poisson point processes (NHPPPs) in \proglang{R}. The included functions are based on three algorithms that provably sample from a target NHPPP: the time-transformation of a homogeneous Poisson process (of intensity one) via the inverse of the integrated intensity function; the generation of a Poisson number of order statistics from a fixed density function; and the thinning of a majorizing NHPPP via an acceptance-rejection scheme. We present a study of numerical accuracy and time performance of the algorithms and advice on which algorithm to prefer in each situation. Functions available in the package are illustrated with simple reproducible examples.
}

%% - \Keywords{} with LaTeX markup, at least one required
%% - \Plainkeywords{} without LaTeX markup (if necessary)
%% - Should be comma-separated and in sentence case.
\Keywords{stochastic point processes, counting processes, discrete event simulation, time-to-event simulation, \proglang{R}}
\Plainkeywords{stochastic point processes, counting processes, discrete event simulation, time-to-event simulation, R}

%% - \Address{} of at least one author
%% - May contain multiple affiliations for each author
%%   (in extra lines, separated by \emph{and}\\).
%% - May contain multiple authors for the same affiliation
%%   (in the same first line, separated by comma).
\Address{
  TA Trikalinos\\
  Department of Health Services, Policy \& Practice\\
  \emph{and}\\
  Department of Biostatistics\\
  School of Public Health\\
  Brown University\\
  RI 02912, USA\\
  E-mail: \email{thomas\_trikalinos@brown.edu}
}

\begin{document}

<<setup, echo=FALSE, message=FALSE, results='hide'>>=
suppressPackageStartupMessages({library(ggplot2)})
library(latex2exp)

suppressWarnings(devtools::dev_mode())
library("nhppp")

options(prompt = "R> ", continue = "+  ", width = 70, useFancyQuotes = FALSE)
set.seed(1)

# set up knit_hooks for plot with optional notes
knit_hooks$set(plot = function(x, options) {
  paste("\n\\end{kframe}\n\\begin{figure}\n",
        "\\includegraphics[width=\\maxwidth]{",
        opts_knit$get("base.url"), paste(x, collapse = "."),
        "}\n",
#        "\\textsc{Note} -- here is some car stuff with notes",
        "\\caption{", options$fig.cap, "}\n",
        "\n\\end{figure}\n\\begin{kframe}\n",
        sep = '')
})

regular_plot <- knit_hooks$get("plot")

pprint <- function(x, digits = 2) format(round(x, digits=digits), nsmall=digits)
pprint3 <- function(x) pprint(x, 3)
@






%% -- Introduction -------------------------------------------------------------

%% - In principle "as usual".
%% - But should typically have some discussion of both _software_ and _methods_.
%% - Use \proglang{}, \pkg{}, and \code{} markup throughout the manuscript.
%% - If such markup is in (sub)section titles, a plain text version has to be
%%   added as well.
%% - All software mentioned should be properly \cite-d.
%% - All abbreviations should be introduced.
%% - Unless the expansions of abbreviations are proper names (like "Journal
%%   of Statistical Software" above) they should be in sentence case (like
%%   "generalized linear models" below).

\section{Introduction} \label{sec:intro}


It is often desirable to simulate series of events (stochastic point processes) so that the intensity of their occurrence varies over time. Examples include events such as the occurrence of death or occurrences of symptoms, infections, or tumors over a person's lifetime. The nonhomogeneous Poisson point process (NHPPP), which generalizes the simpler homogeneous Poisson, Weibull, and Gompertz point processes, is a widely used model for such series of events. NHPPPs can model complicated event patterns given a suitable intensity function. They are therefore a very useful tool in statistical and mathematical model simulation.

A NHPPP has the properties that the number of events in all non-overlapping time intervals are independent random variables and that, within each time interval, the number of events is Poisson distributed. Thus an NHPPP is a memoryless point process. A large number of phenomena may reasonably conform with these properties. In addition, many point processes that are not NHPPPs approach a constant rate Poisson process under a wide range of circumstances. However, there exist phenomena that are not well described by a memoryless point process, such as the occurrence of new infection events during an epidemic wave, where the number of new infections over time depends on the number of infections in the previous time interval. Thus, at least in its early phase, an epidemic wave may be better described by self-exciting point processes that transiently increase the intensity function after a first event. %, with the Hawkes point process being an archetypical example.

The \pkg{nhppp} package in \proglang{R} contains functions for the simulation of NHPPPs over a one-dimensional carrier space, which we will assume to represent time.

We review NHPPPs in Section~\ref{sec:review} and algorithms for sampling from constant rate Poisson point processes in Section~\ref{sec:sample-ppp}. We introduce the three sampling algorithms that are implemented in the package in Section~\ref{sec:sampling}, and illustrate their use in Section~\ref{sec:illustrations}. We discuss special functional forms for the intensity function (constant, piecewise constant, linear, quadratic, and exponential-linear) in Section~\ref{sec:special_cases}. We discuss sampling times from general intensity functions, as well as useful tasks such as sampling conditional on having exactly one and at least one event in a time interval (Section~\ref{sec:general_functions}). We compare \pkg{nhppp} with other \proglang{CRAN} packages that can simulate from one dimensional NHPPPs in Section~\ref{sec:comparisons} and conclude with a discussion (Section~\ref{sec:discuss}). Some algorithms are illustrated with pseudocode in the main text. Other important algorithms are presented in pseudocode in the Appendix.


\section{The Poisson point process} \label{sec:review}
\subsection{Definition}
The Poisson point process is a stochastic series of events on the real line. For some sequence of events, let $N(t, t + \Delta t)$ be the number of events in the interval $[t, t  + \Delta t)$. If for some positive intensity $\lambda$ and as ${\Delta t \rightarrow 0}$
\begin{equation}\label{eq:definition}
    \begin{aligned}
    \Pr[N(t, t + \Delta t) = 0] =&\  1 - \lambda \Delta t +  o(\Delta t), \\
    \Pr[N(t, t + \Delta t) = 1] =&\  \lambda \Delta t +  o(\Delta t), \\
    \Pr[N(t, t + \Delta t) >1] =&\  o(\Delta t),\text{ and } \\
    N(t, t + \Delta t) \indep&\ N(0, t),
    \end{aligned}
\end{equation}
then that series of events is a Poisson point process. In Equation~\eqref{eq:definition}, the third statement demands that events occur one at a time. The fourth statement implies that the process is memoryless: For any time $t_0$, the behavior of the process is independent to what happened before that time.

\subsection{Homogeneous Poisson point process and counting process}\label{sec:ppp-intro}
Assume that the next event after time $t_0$ happens at time $t_0 + X$. It follows from the definition that, for a constant $\lambda$, $X$ is exponentially distributed
\begin{equation}\label{eq:X_PPP}
X \sim \text{Exponential}(\lambda),
\end{equation}
and that, over the interval $[a, b)$ the number of events is Poisson distributed
\begin{equation}\label{eq:N_PPP}
N(a, b) \sim \text{Poisson}(\lambda (b-a)).
\end{equation}

Equation~\eqref{eq:X_PPP} generates the homogeneous Poisson point process $Z_1 = t_0 + X_1, Z_2 = Z_1 + X_2, \dots$, where $Z_i$ is the time of arrival of event $i$ and the inter-arrival times $X_i$ follow~\eqref{eq:X_PPP}. We will use $Z_{(i)}$ to denote the event $i$ when event are ordered in increasing time.

Equation \eqref{eq:N_PPP} describes the corresponding (dual) counting process ${N_1 = N(t_0, Z_1)}, {N_2 = N(t_0, Z_2), \dots}$, where $N_i$ is the total number of events from time $t_0$ to time $Z_i$. The point process (the sequence $[Z_i]$ of event times) and the counting process (the sequence $[N_i]$ of cumulants) are two sides of the same coin.

Sampling from the constant rate point process in~\eqref{eq:X_PPP} is discussed in Section~\ref{sec:sample-ppp}.


\subsection{Non homogeneous Poisson point process and counting process}\label{sec:nhppp-intro}
When the intensity function changes over time, the homogeneous Poisson point process generalizes to its nonstationary counterpart, an NHPPP, with intensity function $\lambda(t) > 0$. Then the number of events over the interval $[a, b)$ becomes
\begin{equation}\label{eq:N_NHPPP}
N(a, b) \sim \text{Poisson}(\Lambda(a, b)),
\end{equation}
where $\Lambda(a, b) = \int_a^b \lambda(t) \ dt$ is the integrated intensity or cumulative intensity of the NHPPP. Equation~\eqref{eq:N_NHPPP} describes the counting process of the NHPPP, which in turn implies a stochastic point process -- a distribution of events over time.

Here the simulation task is to sample event times from the point process that corresponds to intensity function $\lambda(t)$, or equivalently, to the integrated intensity function $\Lambda(t) = \int_0^t \lambda(s) \ ds$ (Section~\ref{sec:sample-nhppp}).

\subsubsection{A note on zero intensity processes}
In~\eqref{eq:definition} $\lambda$ is strictly positive but in~\pkg{nhppp} we allow it to be nonnegative. If $\lambda = 0$, $\\{\Pr[N(t, t + \Delta t) = 0] = 1}$ and ${\Pr[N(t, t + \Delta t) \ge 1] = 0}$. This means that no events occur and the stochastic point process in the interval $(t, t + \Delta t]$ is denegerate. Allowing $\lambda(t) \ge 0$ has no bearing on the results of simulations: If
\begin{equation*}
    \lambda(t)  \begin{cases}
    >0, \text{ for } t \in (a, b] \\
    =0, \text{ for } t \in (b, c] \\
    >0, \text{ for } t \in (c, d]
    \end{cases}
\end{equation*}
we can always ignore the middle interval in which no events happen.

\subsection{Properties that are important for simulation}\label{sec:properties}
\subsubsection{Composability and decomposability of NHPPPs}
The definition~\eqref{eq:definition} implies that NHPPPs are composable: merging two NHPPPs with intensity functions $\lambda_1(t), \lambda_2(t)$ yields a new NHPPP with intensity function $\lambda(t) = \lambda_1(t) + \lambda_2(t)$. The reciprocal is also true: one can decompose an NHPPP with intensity function $\lambda(t)$ into two NHPPPs, one with intensity function $\lambda_1(t) < \lambda(t)$ and one with intensity function ${\lambda_2(t) = \lambda(t)-\lambda_1(t)}$.\footnote{The proof is omitted, but it involves showing that the composition and decomposition yields processes that conform to definition~\eqref{eq:definition}.} An induction argument extends the above to merging and decomposing three or more processes.

The composability and decomposability properties are important for simulation because they
\begin{itemize}
    \item give the flexibility to simulate several parallel NHPPPs independently or to merge them, simulate from the merged process, and then attribute the realized events to the component processes by assigning the $i$-th event to the $j$-th process with probability $\lambda_j(Z_i) / \lambda(Z_i)$, where $\lambda(t) = \sum \lambda_j(t)$.
    \item motivate a general sampling algorithm (Algorithm~\ref{alg:thinning}, ``thinning'') that simulates a target NHPPP with intensity $\lambda_1(t)$ by first drawing events from an easy-to-sample NHPPP with intensity $\lambda(t) >\lambda_1(t)$, and then accepts sample $i$ with probability $\lambda_1(Z_i)/\lambda(Z_i)$.
\end{itemize}

\subsubsection{Transformations of the time axis}
Strictly monotonic transformations of the carrier space of an NHPPP yield an NHPPP. Consider an NHPPP with intensity functions $\lambda(t)$ and a strictly monotonic transformation of the time axis $u: t \mapsto \tau$ that is differentiable once almost everywhere. On the transformed time axis the point process is an NHPPP with intensity function
\begin{equation}\label{eq:transform}
    \rho(\tau) = \lambda(\tau) \left ( \der{u}{t} \right )^{-1}.
\end{equation}

This property is important for simulation because
\begin{itemize}
    \item it motivates the use of another general sampling algorithm (Algorithm~\ref{alg:inversion}, ``inversion''): A smart choice for $u$ yields an easy to sample point process. The event times in the original time scale can be obtained as $Z_i = u^{-1}(\zeta_i)$, where $\zeta_i$ is the $i$-th event in the transformed time axis and $u^{-1}$ is the inverse function of $u$.
    \item given that at least $i$ events have realized in the time interval $(a, b]$, it makes it possible to draw events ${Z_{(j)}, j<i}$ given event $Z_{(i)}$. This is useful for simulating earlier events conditional on the occurrence of a subsequent event. Choosing $u(t) := Z_{(i)} - t$ makes the time count backwards from $Z_{(i)}$. In this reversed clock we draw as if in forward time exactly $i-1$ events $\zeta_{(1)}, \zeta_{(2)}, \dots, \zeta_{(i-1)}$. Back transforming yields all preceding events.
\end{itemize}

Let $\mathcal{I} = (a, b]$ be a compact time interval. Table~\ref{tab:simtasks} summarizes the common simulation tasks, such as simulating single events (at most one, exactly one), a series of events (possibly demanding the occurrence of at least one event), or the occurrence of a prior (event $i-1$ given $Z_{(i)}$). The \pkg{nhppp} package implements functions to simulate these tasks for general $\lambda(t)$ or $\Lambda(t)$.

\input{table/tab_simulation_tasks}

\section{Sampling the constant rate Poisson process}\label{sec:sample-ppp}

Sampling the constant rate Poisson process is straightforward. Algorithms~\ref{alg:PPP_t} and~\ref{alg:PPP_order_stats} are two ways to sample event times in interval $[a, b)$ with constant intensity $\lambda$. Algorithm~\ref{alg:PPP_conditional} describes sampling event times conditional on observing at least $k$ events within the interval of interest.


\subsection{Sequential sampling}\label{sec:PPP_t}

\input{algorithms/alg_ppp_sequential}

Algorithm~\ref{alg:PPP_t} samples events sequentially, using the fact that the inter-event times $X_i$ are exponentially distributed with mean $\lambda^{-1}$. It involves generation only of exponential random variates, which is cheap on modern hardware. To sample at most $k$ events, change the condition for the while loop in line 3 to
\begin{center}
\textbf{while} {$t <b  \ \& \  |\mathcal{Z}| < k$} \textbf{do}.
\end{center}

The package's \fct{ppp\_t} function implements constant-rate sequential sampling that returns a vector with 0 or more event times in the interval $[a, b)$. The \texttt{range\_t} is a two-values vector with the bounds $a, b$. The optional \texttt{tol} argument is used to get an upper bound on the realized number of events -- using it speeds up the algorithm's implementation in \proglang{R}. Setting the optional argument \texttt{only1} to \texttt{TRUE} from its default value of \texttt{FALSE} returns the first event or an empty vector, depending on whether at least one event is drawn in the interval.

<<>>=
library("nhppp")
ppp_t(range_t = c(0, 10), rate = 1, tol = 10^-6, only1 = FALSE)
@

\subsection{Sampling using order statistics}\label{sec:PPP_order_stats}
\input{algorithms/alg_ppp_order_stats}

Algorithm~\ref{alg:PPP_order_stats} first draws the number of events in $[a, b)$ from a Poisson distribution. Conditional on the number of events, the event times $Z_i$ are uniformly distributed over the interval $[a, b)$. The algorithm returns the order statistics [$Z_{(i)}$], obtained by sorting the event times [$Z_i$] in ascending order. It is necessary to generate all event times to generate the order statistics. Thus, to sample at most $k$ events we should return the first up to $k$ times, and line 11 of the Algorithm would be changed to
\begin{center}
\textbf{return} {$\{Z_{(i)} \ | \ i \le k, Z_{(i)} \in \mathcal{Z}\}$}.
\end{center}


The \fct{ppp\_t\_orderstat} function implements constant-rate sampling via the order-statistics algorithm.

<<>>=
ppp_t_orderstat(range_t = c(3.14, 6.28), rate = 1, only1 = FALSE)
@

\subsection{Sampling conditional on observing at least $m$ events}\label{sec:PPP_order_stats}

\input{algorithms/alg_ppp_conditional}

Algorithm~\ref{alg:PPP_conditional} is used to generate a point process conditional on observing at least $m$ events. For example, if $\lambda$ is the intensity of tumor generation, it can be used to simulate times of tumor emergence among patients with at least one ($m=1$) tumor. To return the up to $k$ earliest events, we modify line 11 the same way as for Algorithm~\ref{alg:PPP_order_stats}. As an example, in a lifetime simulation we can sample the time of all-cause death by setting in Algorithm~\ref{alg:PPP_conditional} $m=1$, so that at least one event will happen in $[a, b)$, and $k = 1$, to sample only the time of the first death event $Z_{(1)}$.

To sample exactly $m$ events, change line 1 of Algorithm~\ref{alg:PPP_conditional} to
\begin{center}
$N \gets m$.
\end{center}

Function \fct{ztppp\_t} simulates times conditional on drawing at least one event - i.e., setting $m=0$ in Algorithm~\ref{alg:PPP_conditional}.
<<>>=
ztppp_t(range_t = c(0, 10), rate = 0.001, only1 = FALSE)
@

Function \fct{ppp\_n} simulates times conditional on drawing exactly $m$ events.
<<>>=
ppp_n(size = 4, range_t = c(0, 10))
@

\section[The general sampling algorithms used in nhppp]{The general sampling algorithms used in \pkg{nhppp}}\label{sec:sampling}

The \pkg{nhppp} package uses three well known general sampling algorithms, namely thinning, time warping, and order-statistics. These algorithms are efficiently combined to sample from special cases, including cases where the intensity function is a piecewise constant, linear, quadratic, exponential-linear, or exponential-quadratic function of time, as described in Section~\ref{sec:sample-nhppp-special}.

\subsection{The thinning algorithm}\label{sec:thinning}
The thinning algorithm relies on the decomposability of NHPPPs (Section~\ref{sec:properties}). Let the target NHPPP have intensity function $\lambda(t)$ and $\lambda_*(t) \ge \lambda(t)$ for all $t \in [a, b)$ be a majorizing intensity function. Think of the majorizing function as an easy-to-sample function which is the sum of the intensity of the target point process $\lambda(t)$ and the intensity $\lambda_{reject}(t)$ of its complementary point-process,
$$\lambda_*(t) = \lambda(t) + \lambda_{reject}(t).$$


\input{algorithms/alg_nhppp_thinning}

To sample the earliest $k$ points, one can exit the for loop in lines 4-9 when $k$ events have been sampled in line 7, or, alternatively, return the first up to $k$ points in line 11.

The acceptance-rejection scheme in Algorithm~\ref{alg:NHPPP_thinning} generates proposal samples with intensity function $\lambda_*(t)$ and stochastically attributes them to the target process (which are kept) or its complement (which are discarded).
A measure of the efficiency of Algorithm~\ref{alg:NHPPP_thinning} is the proportion of samples that are accepted, which is
$$\frac{\int_a^b{\lambda(t) \textrm{ d}t}}{\int_a^b{\lambda_*(t) \textrm{ d}t}}$$
on average. Thus, the closer $\lambda_*(t)$ is to $\lambda(t)$, the more efficient the algorithm.

In practice, $\lambda_*(t)$ can be chosen as one of the special cases in Section~\ref{sec:special_cases} for which we have fast sampling algorithms. For example, Algorithm~\ref{alg:lambda_majorizer} in Appendix~\ref{app:piecewise_majorizer} can be used to derive a piecewise constant majorizer function for the general case of a $K$-Lipschitz continuous intensity function.
%\input{algorithms/alg_majorizer}

The \pkg{nhppp} package has two functions that sample from general intensity functions. The first function, \fct{nhppp\_t\_intensity}, expects a user-provided linear ($\lambda_*(t) = \alpha + \beta t$) or exponential-linear ($\lambda_*(t) = e^{\alpha + \beta t}$) majorizer function.

<<>>=
lambda_fun <- function(t) exp(0.02*t)

nhppp_t_intensity(lambda = lambda_fun,         # linear majorizer
lambda_maj = c(intercept = 1.01, slope = 0.03),
exp_maj = FALSE, range_t = c(0, 10), only1 = FALSE)

nhppp_t_intensity(lambda = lambda_fun,         # exp-linear majorizer
lambda_maj = c(intercept = 0.01, slope = 0.03),
exp_maj = TRUE, range_t = c(0, 10), only1 = FALSE)
@


The second function, \fct{nhppp\_t\_intensity\_piecewise}, expects a user-provided piecewise linear majorizer
\begin{align*}
    \lambda_*(t) = \begin{cases}
    \lambda_1 &\textrm{ for } t \in [a_1, b_1) = [a, b_1), \\
    \dots &\\
    \lambda_m &\textrm{ for } t \in [a_m, b_m), \\
    \dots &\\
    \lambda_M &\textrm{ for } t \in [a_M, b_M) = [a_M, b),
    \end{cases}
\end{align*}
which is specified as a vector of length $M+1$ including the points $(a, [b_m]_{m=1}^M)$ and a vector of length $M$ with the values $[\lambda_m]_{m=1}^M$ in each subinterval of $[a, b)$. For example, the following code splits the interval $[0, 10)$ into $M=10$ subintervals of length one. Because \fct{lambda\_fun} is strictly increasing, its value at the upper bound of each subinterval is the supremum of the interval (Appendix~\ref{app:piecewise_majorizer}, Algorithm~\ref{alg:lambda_majorizer}).


<<>>=
nhppp_t_intensity_piecewise(lambda = lambda_fun,
lambda_maj_vector = lambda_fun(1:10),
times_vector = 0:10,
only1 = FALSE)
@



\subsection{The time-warping algorithm }\label{sec:time-warp}
As mentioned in Section~\ref{sec:properties}, strictly monotonic transformations of the carrier space (here, time) of a Poisson Point Process yield another Poisson Point Process. In equation~\eqref{eq:transform}, choosing the transformation $\tau = u(t) = \Lambda(t)$, $\der{u(t)}{t} =  \lambda(t)$ results in $\rho(\tau) = 1$.

This means (detailed proof omitted) that we can sample points from a Poisson point process with intensity one over the interval $[\tau_a, \tau_b) = [\Lambda(a), \Lambda(b))$. Via a similar argument, we transform event times sampled on the transformed scale back to the original scale using $g(t)=\Lambda^{-1}(\tau)$. The transformations $u(\cdot), g(\cdot)$ are not unique -- at least up to the group of affine transformations.

Algorithm~\ref{alg:NHPPP_inversion} follows the above rationale.

Function \fct{nhppp\_t\_cumulative\_intensity\_inversion} works with a cumulative intensity function $\Lambda(t)$ and its inverse $\Lambda^{-1}(z)$, if available. If the inverse function is not available (argument \texttt{Lambda\_inv = NULL}) the Brent bisection algorithm is used to invert $\Lambda(t)$ numerically, at a performance cost.

<<>>=
Lambda_fun <- function(t) 50 * exp(0.02 * t) - 50
Lambda_inv_fun <- function(z) 50 * log((z + 50) / 50)

nhppp_t_cumulative_intensity_inversion(Lambda = Lambda_fun,
Lambda_inv = Lambda_inv_fun,
range_t = c(5, 10.5),
range_L = Lambda_fun(c(5, 10.5)),
only1 = FALSE)
@




\input{algorithms/alg_nhppp_inversion}

\subsection{The order statistics algorithm}\label{sec:order-stats}
The general order statistics algorithm (Algorithm~\ref{alg:NHPPP_order_stats}) is a direct generalization of Algorithm~\ref{alg:PPP_order_stats}. It first draws the number $N$ of realized events. Conditional on $N$ (proof omitted)
\begin{equation}\label{eq:nhppp_orderstats1}
\begin{aligned}
U_{(i)} &= \frac{\Lambda(Z_{(i)}) - \Lambda(a)}{\Lambda(b)- \Lambda(a)} \sim \textrm{Uniform}(0,1), \\
Z_{(i)} &= \Lambda^{-1} \Big ( \Lambda(a) + U_{(i)} \big( \Lambda(b)- \Lambda(a) \big) \Big).
\end{aligned}
\end{equation}
Algorithm~\ref{alg:NHPPP_order_stats} makes the above explicit. If $\Lambda(t)$ is a positive linear function of time, $\lambda$ is constant and Algorithm~\ref{alg:NHPPP_order_stats} becomes Algorithm~\ref{alg:PPP_order_stats}.

\input{algorithms/alg_nhppp_order_stats}

Sampling up to $k$ earliest points means returning the up to $k$ first times.

To sample conditional on observing at least $m$ events in the interval $[a, b)$, modify line 1 of Algorithm~\ref{alg:NHPPP_order_stats} to sample from a $(m-1)$-truncated Poisson distribution (Appendix~\ref{app:conditional_sampling}, Algorithm~\ref{alg:NHPPP_conditional}).
\begin{center}
$N \gets N \sim \mathrm{TruncatedPoisson}_{N \ge m}\big(\Lambda(b) - \Lambda(a)\big)$.
\end{center}


Function \fct{nhppp\_t\_cumulative\_intensity\_orderstats} works with a cumulative intensity function $\Lambda(t)$ and its inverse $\Lambda^{-1}(z)$, if available.
Function \fct{ztnhppp\_t\_cumulative\_intensity} conditions that at least one event is sampled in the interval. If the inverse function is not available (argument \texttt{Lambda\_inv = NULL}) the Brent bisection algorithm is used to invert $\Lambda(t)$ numerically, at a performance cost.

<<>>=
nhppp_t_cumulative_intensity_orderstats(Lambda = Lambda_fun,
Lambda_inv = Lambda_inv_fun,
range_t = c(4.1, 7.6),
only1 = FALSE)

ztnhppp_t_cumulative_intensity(Lambda = Lambda_fun,
Lambda_inv = Lambda_inv_fun,
range_t = c(4.1, 7.6),
only1 = FALSE)
@





\section{Special cases}\label{sec:special_cases}

The \pkg{nhppp} package implements several special cases where the intensity function $\lambda(\cdot)$, the integrated intensity function $\Lambda(\cdot)$ and its inverse $\Lambda^{-1}(\cdot)$ have straightforward analytical expressions.

\subsection{Sampling a piecewise constant NHPPP}\label{sec:sample-nhppp-pc}

Function {\fct{sim\_ppp\_piecewise}} samples a piecewise constant intensity function based on Algorithm~\ref{alg:NHPPP_inversion}.
<<>>=
ppp_t_piecewise(rates_vector = 1:5, times_vector = 0:5, only1 = FALSE,
                zero_truncated = FALSE)
@


\subsection{Sampling NHPPPs with linear and exponential-linear intensities}\label{sec:sample-nhppp-special}

Functions \fct{nhppp\_t\_intensity\_linear} and \fct{ztnhppp\_t\_intensity\_linear} sample zero or more and at least one event, respectively, from NHPPPs with linear intensity functions. An optional argument (\texttt{only1}) returns the first event only.
\begin{align*}
    \lambda(t) =
    \begin{cases}
        \alpha + \beta t &\text{ for } t \in [a, b), t>-\frac{\alpha}{\beta} \\
        0 &\textrm{ otherwise}
    \end{cases}.
\end{align*}

<<>>=
nhppp_t_intensity_linear(alpha = 3, beta = -0.5, range_t = c(0, 10),
                         only1 = FALSE)
ztnhppp_t_intensity_linear(alpha = 0.5, beta = 0.2, range_t = c(0, 10),
                           only1 = FALSE)
@

An analogous set of functions (\fct{[nhppp|ztnhppp]\_t\_intensity\_exponential}) samples from exponential-linear intensity functions

\begin{align*}
    \lambda(t) =
    \begin{cases}
        e^{\alpha + \beta t} &\text{ for } t \in [a, b) \\
        0 &\textrm{ otherwise}
    \end{cases}.
\end{align*}

<<>>=
nhppp_t_intensity_exponential(alpha = 1, beta = -0.02, range_t = c(8, 10),
                              only1 = FALSE)
@

<<>>=
ztnhppp_t_intensity_exponential(alpha = 1, beta = -0.02, range_t = c(5, 10),
                                only1 = FALSE)
@


%% -- Illustrations ------------------------------------------------------------

%% - Virtually all JSS manuscripts list source code along with the generated
%%   output. The style files provide dedicated environments for this.
%% - In R, the environments {Sinput} and {Soutput} - as produced by Sweave() or
%%   or knitr using the render_sweave() hook - are used (without the need to
%%   load Sweave.sty).
%% - Equivalently, {CodeInput} and {CodeOutput} can be used.
%% - The code input should use "the usual" command prompt in the respective
%%   software system.
%% - For R code, the prompt "R> " should be used with "+  " as the
%%   continuation prompt.
%% - Comments within the code chunks should be avoided - these should be made
%%   within the regular LaTeX text.


\section[Comparisons with other R packages]{Comparisons with other \proglang{R} packages}\label{sec:other-R-packages}

Table~\ref{tab:R-packages} lists seven \proglang{R} packages that simulate from NHPPPs, including \pkg{nhppp}.
Packages \pkg{IndTestPP}~\citep{IndTestPP-package} and \pkg{reda}~\citep{reda-package} use both the thinning and inversion algorithms.  \pkg{PtProcess}~\citep{PtProcess-package}, \pkg{reda}, \pkg{simEd}~\citep{simEd-package}, and \pkg{spatstat.random}~\citep{spatstat-package} can simulate NHPPPs from intensity functions over a user-specified inverval.
\pkg{IndTestPP} requires an approximation of the intensity function by means of a vector of intensity function evaluations every one time unit. The length of the interval $[a, b)$ is inferred from the length of the intensity-values vector and is measured in integer time units. This limits the resolution with which the intensity function can be approximated. The function \fct{simNHP.fun} from \pkg{NHPoisson}~\citep{NHPoisson-package} returns the (index of) the unit-time interval in which the simulated events is drawn instead of the actual event time. Except for \pkg{reda} (and \pkg{nhppp}), other packages did not have the option to sample only the first event. Only \pkg{nhppp} can use a user-provided random number generator object.

\input{table/tab_other_R_packages}


\section{Illustrations} \label{sec:illustrations}

Depending on the application, we may have access to the intensity function
or the integrated intensity function.
We will compare sampling from a highly nonlinear and nonmonotone intensity function for which the integrated intensity function is known analytically. We will provide each sampling function the arguments it requires.


\subsection{Simulated target NHPPP}\label{sec:illustration-target}

<<echo=FALSE, include=FALSE>>=
nsim <- 10^4
@


Consider the example
\begin{equation}\label{eq:illustration}
\begin{aligned}
\lambda(t) &= e^{rt}(1+\sin t), \\
\Lambda(t) &= \dfrac{e^{rt}(r\sin t - \cos t)}{r^2+1}+\dfrac{e^{rt}}{r} - \dfrac{r^2-r+1}{r^3+r}
\end{aligned}
\end{equation}
of a sinusoidal intensity function $\lambda(t)$ scaled to have an exponential amplitude and one of its antiderivatives $\Lambda(t)$, with such a constant term that $\Lambda(0)=0$.  For the numerical study we set $r=0.2$ and $t \in [0, 6\pi)$. There is no easy analytic inverse
function for this example, but \pkg{nhppp} functions that need it can obtain it numerically.
Below, we also construct numerically \fct{Li\_fun}, the $\Lambda^{-1}(z)$ function for this example, to approximate the best time performance of functions that use the inversion and order statistics algorithms in the numerical study.
<<eq7.functions>>=
l_fun <- function(t) (1+sin(t)) * exp(0.2 * t)
L_fun <- function(t) exp(0.2 * t) * (0.2 * sin(t) -  cos(t)) / 1.04 +
  exp(0.2 * t) / 0.2 - 4.038462
Li_fun <- approxfun(x = L_fun(seq(1, 6 * pi, 10^-3)),
                    y = seq(1, 6 * pi, 10^-3))
@

<<eq7.findK, echo=FALSE, include=FALSE>>=
# to get a bound for K
abs_l_prime_fun <- function(t) abs((0.2 + 0.2 * sin(t) + cos(t))) * exp(0.2 * t)
K <- abs_l_prime_fun(6*pi)
@

<<majorizers, echo=FALSE, include=FALSE>>=
M <- 20
x_breaks <- seq(0, 6 * pi, length.out = M+1)
l_m <- get_piecewise_linear_majorizer(fun = l_fun, breaks = x_breaks,
                                     is_monotone = FALSE, K = K)
l_star <- stats::approxfun(x = x_breaks[1:M], y = l_m, method = "constant",
                           rule = 2)

l_m2 <- c()
for(m in 1:M){
  x_tmp <- seq(x_breaks[m], x_breaks[m+1], length.out = 10000)
  y_tmp <- l_fun(x_tmp)
  l_m2 <- c(l_m2, y_tmp[which(y_tmp == max(y_tmp))])
}
l_star2 <- stats::approxfun(x = x_breaks[1:M], y = l_m2, method = "constant",
                           rule = 2)
rm(list = c("m", "x_tmp", "y_tmp"))
@


<<illustration-plot, fig.cap="The $\\lambda(t)$ (left) and $\\Lambda(t)$ used in the illustration. Also shown three majorizing functions (left panel, marked a, b, c) that are used with the thinning algorithm in the analyses.", fig.height=4, fig.width=8, echo=FALSE>>=
plot_base <- ggplot(data = data.frame(x = seq(0, 6 * pi, length.out =200)), aes(x)) + xlab("t")  + theme_bw() + theme(text = element_text(size=18))
plot_l <- plot_base +
  geom_function(fun = l_fun, xlim = c(0, 6 * pi), color = "red") +
  geom_function(fun = function(x) l_fun(6 * pi),
                xlim = c(0, 6 * pi), n = 200, color = "blue", linetype = "longdash") +
  geom_step(data = data.frame(x = x_breaks, l_m = l_m[c(1:M, M)]), aes(y=l_m),
            color = "black") +
  geom_step(data = data.frame(x = x_breaks, l_m2 = l_m2[c(1:M, M)]), aes(y=l_m2),
            color = "black", linewidth = 1) +
  geom_text(aes(x = 1, y = l_fun(6*pi)+3, label = "a")) +
  geom_text(aes(x = 1, y = l_star(1)+3, label = "b")) +
  geom_text(aes(x = 1, y = l_star2(1)+3, label = "c")) +
  ylab("Intensity")
plot_L <- plot_base +
  geom_function(fun = L_fun, xlim = c(0, 6 * pi), color = "red") +
  ylab("Integrated intensity")
gridExtra::grid.arrange(plot_l, plot_L, nrow = 1)
@


Figure~\ref{fig:illustration-plot} graphs the intensity function and three majorizing functions over the interval of interest, which will be needed for the thinning algorithm.

The first, $\lambda_{*a}(t) = \Sexpr{pprint(l_fun(6*pi), 2)}$, shown as a dashed blue line, is equal to the maximum of the intensity function. A constant majorizer may be a practical choice when only an upper bound is known for $\lambda(t)$.
The efficiency of the thinning algorithm using this majorizer is
$\Sexpr{ pprint(L_fun(6*pi)/(l_fun(6*pi)*6*pi), 3) }$.

The second, $\lambda_{*b}(t)$, shown as a thin black line, is a piecewise constant envelope obtained automatically from Algorithm~\ref{alg:lambda_majorizer} (Appendix~\ref{app:piecewise_majorizer}) with $\Sexpr{M}$ equal-length subintervals and $K \approx \Sexpr{pprint(K, 2)}$, where $K$ is equal to the maximum value of $|\der{\lambda(t)}{t}|$ in the interval, attained at $6\pi$.
The efficiency of the thinning algorithm using this majorizer is
$\Sexpr{pprint(L_fun(6*pi)/sum(l_star(x_breaks[1:M])*(6*pi / M)), 3) }$.

The third, $\lambda_{*c}(t)$, shown as a thicker black line, is a tighter piecewise constant majorizer with $\Sexpr{M}$ equal-length subintervals that is constructed by finding a least upper bound in each subinterval. The efficiency of the thinning algorithm with the third
majorizer is
$\Sexpr{pprint(L_fun(6*pi)/sum(l_star2(x_breaks[1:M])*(6*pi / M)), 3) }$.


\subsection{Simulation functions and algorithms}\label{sec:methods-sim}

We sample series of events from the target NHPPP using the implementations in Table~\ref{tab:R-packages}. We repeat this simulation $\Sexpr{nsim}$ times, recording all simulated points and execution times.

From the \pkg{nhppp} package we use
\begin{enumerate}
\item  two functions that take as argument the intensity function and are based on Algorithm~\ref{alg:NHPPP_thinning} (thinning): \fct{nhppp\_t\_intensity}, which uses linear majorizers like $\lambda_a$, and \fct{nhppp\_t\_intensity\_piecewise} uses piecewise constant majorizers line $\lambda_b$ and $\lambda_c$.
\item  Function \fct{nhppp\_t\_cumulative\_intensity\_inversion}, which takes as argument the cumulative intensity function $\Lambda(t)$ and is based on Algorithm~\ref{alg:NHPPP_inversion} (time-warping), and
\item  function \fct{nhppp\_t\_cumulative\_intensity\_orderstats}, which also uses $\Lambda(t)$ and is based on Algorithm~\ref{alg:NHPPP_order_stats} (order statistics).
\end{enumerate}

\subsection{Simulation performance with respect to number of points}\label{sec:sim-counts}

To assess simulation performance we compare with the simulated process the empirical distributions of both the simulated counts and the realized event times with each function using the metrics in Table~\ref{tab:sim_metrics}.

For the goodness of fit calculations, we partition the ray $(0, \infty)$ (the range of a Poisson random variable) into bins $[0, L), [L, L+1), \dots, [U, \infty)$, where $L, U$ are the $0.001$ and $0.999$ percentiles of the Poisson distribution. We index bins with $x \in \{ 1, \dots, U-L+2\}$. In the example, $L = \Sexpr{stats::qpois(0.001, L_fun(6*pi)-L_fun(0))}$ and $U = \Sexpr{stats::qpois(0.999, L_fun(6*pi)-L_fun(0))}$. $O_x$ is the observed number of simulated counts in $x$ of the $K$ simulations. $E_x$ is the expected number of counts per bin, which is $K$ times the integral of the Poisson distribution density with parameter $\Lambda(6\pi)-\Lambda(0)$ over each bin.

We also calculate the Wasserstein-1 distance $W_1$ between the simulated and theoretical
distributions over all $K$ simulations ($W_1 = 0$ implies perfect fit) and a permutation based $p$~value for whether $W_1 \neq 0$. $W_1$ is the smallest probability mass that has to be redistributed so that one distribution matches the other. $W_1$ is equal to the
unsigned area between the cumulative distribution functions of the compared distributions.

\input{table/tab_simulation_metrics}

<<counts-results,echo=FALSE, include=FALSE, cache=TRUE>>=

nhppp_InvOSThin <- function() {
  Thinning <- nhppp::nhppp_t_intensity(
    lambda = l_fun,
    lambda_maj = l_fun(6*pi),
    range_t = c(0, 6*pi),
    only1 = FALSE
  )
  Inversion <- nhppp::nhppp_t_cumulative_intensity_inversion(
    Lambda = L_fun,
    Lambda_inv = Li_fun, # numbers same with this NULL
    range_t = c(0, 6*pi),
    only1 = FALSE
  )
  OrderStats <- nhppp::nhppp_t_cumulative_intensity_orderstats(
    Lambda = L_fun,
    Lambda_inv = Li_fun,  # numbers same with this NULL
    range_t = c(0, 6*pi),
    only1 = FALSE
  )
  return(list(
    "Thinning" = Thinning,
    "Inversion" = Inversion,
    "Order statistics" = OrderStats

  ))
}

nhppp_traj <- parallel::mcmapply(
  function(i) {
    nhppp_InvOSThin()
  },
  1:nsim,
  mc.cores = parallel::detectCores() - 1
)

nhppp_count <- apply(nhppp_traj, 2, function(x) sapply(x, length))

mu <- L_fun(6*pi)-L_fun(0)
t <- as.integer(seq(qpois(0.0001, mu), qpois(0.9999, mu), length.out = nsim))
d <- dpois(t, mu)

# Target vs. simulated count distributions
# better + stat_ecdf()
p1 <- ggplot(NULL) +
  geom_line(aes(x = t, y = d, linetype = "Theoretical", color = "Theoretical")) +
  geom_density(aes(x = nhppp_count[1, ], linetype = "Inversion", color = "Inversion")) +
  geom_density(aes(x = nhppp_count[2, ], linetype = "OrderStats", color = "OrderStats")) +
  geom_density(aes(x = nhppp_count[3, ], linetype = "Thinning", color = "Thinning")) +
  labs(x = "Count", y = "Density", linetype = "") +
  scale_linetype_manual(
    name = "",
    values = c(
      "Inversion" = 4,
      "OrderStats" = 3,
      "Thinning" = 2,
      "Theoretical" = 1
    )
  ) +
  scale_colour_manual(
    name = "",
    values = c(
      "Inversion" = "#0072B2",
      "OrderStats" = "black",
      "Thinning" = "#D55E00",
      "Theoretical" = "#999999"
    )
  ) +
  theme_bw()
# ggsave("count_densities.pdf", p1, width = 10, height = 7, units = "cm")
p1


# Metrics with respect to the number of events in interval
bias_count <- function(x, digits) {
  # $B_\mu$
  mean_obs <- mean(x)
  bN <- mean(x - mu)
  bNr <- (bN / mu) * 100 # as percentage

  # $B_V$
  var_obs <- var(x)
  bV <- var(x) - mu
  bVr <- (bV / mu) * 100 # as percentage

  # O, E counts
  pr1 <- seq(0.0001, 0.999, length.out = 100)
  E <- qpois(pr1, mu)
  O <- quantile(x, pr1)

  # Goodness of Fit p value
  GOF <- sum(((O - E)^2) / E)
  GOF_pval <- pchisq(GOF, length(O) - 1, lower.tail = F)

  # CIs
  pr2 <- c(0.025, 0.05, 0.125, 0.25, 0.75, 0.875, 0.95, 0.975)
  th <- qpois(pr2, mu) # theoretical percentiles
  emp <- as.integer(quantile(x, pr2)) # empirical percentiles
  names(th) <- names(emp) <- paste0(pr2 * 100, "%")

  # W-1 distance and p value
  ed <- density(x)
  set.seed(123)
  td <- stats::dpois(as.integer(ed[[1]]), mu)
  w1 <- twosamples::wass_test(ed$y, td)
  w1_dts <- twosamples::dts_test(ed$y, td)

  values <- c(
    `Sample mean` = pprint(mean_obs, digits),
    `$B_\\mu$`     = pprint(bN, digits),
    `$B_{\\mu, rel}$` = pprint(bNr, digits),
    `Sample variance` = pprint(var_obs, digits),
    `$B_V$` = pprint(bV, digits),
    `$B_{V, rel}$` = pprint(bVr, digits),
    `Goodness of fit, $\\chi^2$ [$p$~value]` = paste0(pprint(GOF, digits), " [", pprint(GOF_pval, digits), "]"),
    `$W_1$ [$p$~value]` = paste0(pprint(w1[1], digits), " [", pprint(w1[2], digits), "]"),
    `$W_1$-weighted [$p$~value]` = paste0(pprint(w1_dts[1], digits), " [", pprint(w1_dts[2], digits), "]"),
    `Coverage 95\\% CI` = paste0("[", emp[1], "; ", emp[8], "]"),
    `Coverage 90\\% CI` = paste0("[", emp[2], "; ", emp[7], "]"),
    `Coverage 75\\% CI` = paste0("[", emp[3], "; ", emp[6], "]"),
    `Coverage 50\\% CI` = paste0("[", emp[4], "; ", emp[5], "]")
  )
  names(values)[length(values)-3] <- c(paste0("Theoretical 95\\% CI = [", th[1], ", ", th[8], "]"))
  names(values)[length(values)-2] <- c(paste0("Theoretical 90\\% CI = [", th[2], ", ", th[7], "]"))
  names(values)[length(values)-1] <- c(paste0("Theoretical 75\\% CI = [", th[3], ", ", th[6], "]"))
  names(values)[length(values)-0] <- c(paste0("Theoretical 50\\% CI = [", th[4], ", ", th[5], "]"))


  return(values)
}

# Results
metrics <- apply(nhppp_count, 1, bias_count, digits = 3)
@

The results are in the following table



<<metrics-table, results='asis', echo=FALSE>>=
print(xtable::xtable(metrics, type="latex"),
      sanitize.text.function = identity, scalebox = 1)
@







%% -- Summary/conclusions/discussion -------------------------------------------

\section{Summary and discussion} \label{sec:summary}

\begin{leftbar}
As usual \dots
\end{leftbar}


%% -- Optional special unnumbered sections -------------------------------------

\section*{Computational details}

\begin{leftbar}
If necessary or useful, information about certain computational details
such as version numbers, operating systems, or compilers could be included
in an unnumbered section. Also, auxiliary packages (say, for visualizations,
maps, tables, \dots) that are not cited in the main text can be credited here.
\end{leftbar}

The results in this paper were obtained using
\proglang{R}~4.3.1 with the
\pkg{XXXX}~7.3.47 packages. \proglang{R} itself
and all packages used used here are available from the Comprehensive
\proglang{R} Archive Network (CRAN) at
\url{https://CRAN.R-project.org/}.


\section*{Acknowledgments}
This work was funded from grant U01CA265750 (Trikalinos, Jalal) from the National Cancer Institute.
We thank the investigators of the Cancer Incidence and Surveillance Modeling Network (CISNET)
Bladder Cancer Site Stavroula Chrysanthopoulou, Jonah Popp, Fernando Alarid-Escudero,
Hawre Jalal, and David Garibay for useful discussions.

%% -- Bibliography -------------------------------------------------------------
%% - References need to be provided in a .bib BibTeX database.
%% - All references should be made with \cite, \citet, \citep, \citealp etc.
%%   (and never hard-coded). See the FAQ for details.
%% - JSS-specific markup (\proglang, \pkg, \code) should be used in the .bib.
%% - Titles in the .bib should be in title case.
%% - DOIs should be included where available.

\bibliography{refs}


%% -- Appendix (if any) --------------------------------------------------------
%% - After the bibliography with page break.
%% - With proper section titles and _not_ just "Appendix".

\newpage
\begin{appendix}

\section{Piecewise constant majorizer functions}\label{app:piecewise_majorizer}

Let $\lambda(t)$ be a $K$-Lipschitz continuous intensity function, i.e., an intensity function where $|(\lambda(b) - \lambda(a))| \le K|b-a|$, with $K$ known. Algorithm~\ref{alg:lambda_majorizer} finds a piecewise constant majorizing function $\lambda_*(t)$. Starting from a partition of the time interval in time steps (not necessarily equal) it finds an upper bound for $\lambda$ within the each partition.

If $\lambda(t)$ is monotonic, the least upper bound (supremum) is always found at the extremes of the interval and no knowledge of $K$ is required.

The algorithm should be started with a good partitioning of the time interval. In practice, it is generally easy to specify equispaced intervals that are fine enough and impose little computational penalty for the application.

The \pkg{nhppp}
function \fct{get\_piecewise\_linear\_majorizer} implements Algorithm~\ref{alg:lambda_majorizer}. Functions \fct{ppp\_t\_piecewise} and \fct{nhppp\_t\_piecewise} expect the majorizer function values as an argument.
<<app-majorizer>>=
get_piecewise_linear_majorizer(fun = abs, breaks = -5:5, is_monotone = FALSE,
                               K = 1)
@


\input{algorithms/alg_majorizer}

\newpage
\section{Conditional sampling from NHPPPs} \label{app:conditional_sampling}
Algorithm~\ref{alg:NHPPP_conditional} is a direct modification of the order statistics Algorithm~\ref{alg:NHPPP_order_stats} (Line 1 modified, in red font).
To sample exactly $m$ points, change line 1 of Algorithm~\ref{alg:NHPPP_conditional} to
\begin{center}
$N \gets m$.
\end{center}
To sample up to $k$ earliest points, replace line 11 with in Algorithm~\ref{alg:NHPPP_conditional} with
\begin{center}
\textbf{return} {$\{Z_{(i)} \ | \ i \le k, Z_{(i)} \in \mathcal{Z}\}$}.
\end{center}

\input{algorithms/alg_nhppp_conditional}







\end{appendix}
\newpage
%% -----------------------------------------------------------------------------


\end{document}
